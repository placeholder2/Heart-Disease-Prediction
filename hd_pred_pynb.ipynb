{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/placeholder2/Heart-Disease-Prediction/blob/main/hd_pred_pynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Heart Disease Prediction**\n",
        "**Using XGBoost and over-sampling methods** \n",
        "\n",
        " \n",
        "The main metric I'll be using to evaluate performance of the models is recall, although I'll also keep an eye on precision and f1 scores for better comparison. Accuracy is not very reliable due to lack of balance in the dataset, but it'll help evaluating in comparing over-sampling techniques."
      ],
      "metadata": {
        "id": "yHnr8jZH1VAe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries and Data"
      ],
      "metadata": {
        "id": "KcRx7uZu3EvN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgIG1KJSLn1j"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import joblib\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV,PredefinedSplit\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from imblearn.over_sampling import ADASYN,RandomOverSampler, SMOTE\n",
        "from imblearn.pipeline import make_pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dY0BuByFL9-S",
        "outputId": "1dad9b75-b720-4bb2-9e4e-8383ffce80d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0f3MeZWiMEMK"
      },
      "outputs": [],
      "source": [
        "file = open('/content/drive/MyDrive/Colab Notebooks/HD/dataset_dict.pkl', \"rb\")\n",
        "data = joblib.load(file)\n",
        "X_train,y_train,X_test,y_test,X_val,y_val = data.values()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model):\n",
        "  '''Function returning y_pred'''\n",
        "    \n",
        "  model.fit(X_train, y_train)\n",
        "  return model.predict(X_test)"
      ],
      "metadata": {
        "id": "XDfhcFMy0Cir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsmIkvcQKOR_"
      },
      "outputs": [],
      "source": [
        "def evaluate(y_pred):\n",
        "  '''Function to evaluate clf performance '''\n",
        "\n",
        "\n",
        "  precision = precision_score(y_test, y_pred)\n",
        "  recall = recall_score(y_test, y_pred)\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "  report = f'Precision: {precision}\\nAccuracy: {accuracy}\\nRecall: {recall}\\nF1: {f1}'\n",
        "  print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Baseline**\n",
        "**Classification with XGBoost**"
      ],
      "metadata": {
        "id": "I9jP-6De3Igm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXbs-SNPJHbE"
      },
      "outputs": [],
      "source": [
        "xgb_normal = XGBClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLv-TyplKguv",
        "outputId": "faa67179-b389-4853-8073-d97f40676912"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.5566502463054187\n",
            "Accuracy: 0.9255780593599509\n",
            "Recall: 0.05131698455949137\n",
            "F1: 0.09397089397089396\n"
          ]
        }
      ],
      "source": [
        "evaluate(predict(xgb_normal))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Really low recall, also the overall performance is rather weak."
      ],
      "metadata": {
        "id": "92G75PMB9Sfa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Applying over-sampling**\n",
        "This time I will use following methods, but there exists a few more, also under-sampling or combination of both types of balancing dataset could be a great idea. \\\n",
        "\n",
        "**RandomOverSampler** - Over-sampling the minority class by picking samples at random with replacement. \\\n",
        "\\\n",
        "**SMOTE (Synthetic Minority Over-sampling Technique)** - Selecting examples that are close in the feature space, drawing a line between the examples in the feature space and drawing a new sample at a point along that line.\\\n",
        "\\\n",
        "**ADASYN (Adaptive Synthetic Sampling Method)** - Modification of SMOTE. Generates different number of samples depending on an estimate of the local distribution of the class to be oversampled.\\\n"
      ],
      "metadata": {
        "id": "u3zQXS9b3R6H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JC4FxQvPBoB"
      },
      "outputs": [],
      "source": [
        "models = [\n",
        "  make_pipeline(RandomOverSampler(random_state=42), xgb_normal),\n",
        "  make_pipeline(SMOTE(random_state=42), xgb_normal),\n",
        "  make_pipeline(ADASYN(random_state=42), xgb_normal),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nXdohCAN2wF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcf4016d-89e4-46dc-8fd9-80891d2c7b01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "randomoversampler\n",
            "\n",
            "Precision: 0.1920017434891577\n",
            "Accuracy: 0.7317189794733426\n",
            "Recall: 0.8001816530426885\n",
            "F1: 0.30969329466561213\n",
            "\n",
            "smote\n",
            "\n",
            "Precision: 0.2588357588357588\n",
            "Accuracy: 0.861402370299532\n",
            "Recall: 0.45231607629427795\n",
            "F1: 0.3292561983471074\n",
            "\n",
            "adasyn\n",
            "\n",
            "Precision: 0.25353283458021614\n",
            "Accuracy: 0.8640322415383039\n",
            "Recall: 0.41553133514986373\n",
            "F1: 0.31491997934950955\n"
          ]
        }
      ],
      "source": [
        "for model in models:\n",
        "  name = list(model.named_steps)[0]\n",
        "  print('\\n' + name + '\\n')\n",
        "  evaluate(predict(model))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best one is randomoversampler."
      ],
      "metadata": {
        "id": "xPEbMVIP-Tlb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Hyperparameter tuning**\n"
      ],
      "metadata": {
        "id": "KbR0KR9Q-HYh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "l8GTtTdAwuN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Best model\n",
        "model = models[0]\n",
        "\n",
        "#Hyperparameters\n",
        "params = {\n",
        "    'xgbclassifier__eval_metric' : ['logloss','error'],\n",
        "    'xgbclassifier__n_estimators': [50,100,150],\n",
        "    'xgbclassifier__learning_rate': [0.01,0.1],\n",
        "    'xgbclassifier__max_depth' : [6,8]\n",
        "}\n",
        "\n",
        "#PredefinedSplit\n",
        "split_index = [-1]*len(X_train) + [0]*len(X_val)\n",
        "X = np.concatenate((X_train, X_val), axis=0)\n",
        "y = np.concatenate((y_train, y_val), axis=0)\n",
        "pds = PredefinedSplit(test_fold = split_index)"
      ],
      "metadata": {
        "id": "IwqeTFgN-FTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid = GridSearchCV(estimator = model,\n",
        "                   cv=pds,\n",
        "                   param_grid=params,\n",
        "                   scoring='recall',\n",
        "                   n_jobs= -1,\n",
        "                   verbose = 3)\n",
        "\n",
        "grid.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzw26qMCY5AY",
        "outputId": "0a9d5255-ed2e-4992-c2c2-400490c421ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 1 folds for each of 24 candidates, totalling 24 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
              "             estimator=Pipeline(steps=[('randomoversampler',\n",
              "                                        RandomOverSampler(random_state=42)),\n",
              "                                       ('xgbclassifier', XGBClassifier())]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'xgbclassifier__eval_metric': ['logloss', 'error'],\n",
              "                         'xgbclassifier__learning_rate': [0.01, 0.1],\n",
              "                         'xgbclassifier__max_depth': [6, 8],\n",
              "                         'xgbclassifier__n_estimators': [50, 100, 150]},\n",
              "             scoring='recall', verbose=3)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZvntcTBJFX2",
        "outputId": "bde53da5-9f2b-49ab-ba89-0736767457eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'xgbclassifier__eval_metric': 'logloss',\n",
              " 'xgbclassifier__learning_rate': 0.01,\n",
              " 'xgbclassifier__max_depth': 6,\n",
              " 'xgbclassifier__n_estimators': 100}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = grid.best_estimator_\n",
        "\n",
        "evaluate(predict(best_model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VK9o5kE397vb",
        "outputId": "fe9ca13e-d6ab-40e0-e960-bdc31ce1919d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.1769727047146402\n",
            "Accuracy: 0.7024830082994638\n",
            "Recall: 0.8097184377838329\n",
            "F1: 0.2904618392115338\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMRfmuEhMt5qnoJEsTSStgs",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}